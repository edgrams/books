{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "standard tokenizer for thai language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tokens\" : [\n",
      "    {\n",
      "      \"token\" : \"สวัสดี\",\n",
      "      \"start_offset\" : 0,\n",
      "      \"end_offset\" : 6,\n",
      "      \"type\" : \"<SOUTHEAST_ASIAN>\",\n",
      "      \"position\" : 0\n",
      "    },\n",
      "    {\n",
      "      \"token\" : \"ผมมาจากกรุงเทพฯ\",\n",
      "      \"start_offset\" : 7,\n",
      "      \"end_offset\" : 22,\n",
      "      \"type\" : \"<SOUTHEAST_ASIAN>\",\n",
      "      \"position\" : 1\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "curl -XGET 'localhost:9200/_analyze?tokenizer=standard&pretty' -H 'Content-Type: application/json' -d'\n",
    "{\n",
    "  \"text\": \"สวัสดี ผมมาจากกรุงเทพฯ\" \n",
    "}\n",
    "'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "icu tokenizer for thai language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tokens\" : [\n",
      "    {\n",
      "      \"token\" : \"สวัสดี\",\n",
      "      \"start_offset\" : 0,\n",
      "      \"end_offset\" : 6,\n",
      "      \"type\" : \"<ALPHANUM>\",\n",
      "      \"position\" : 0\n",
      "    },\n",
      "    {\n",
      "      \"token\" : \"ผม\",\n",
      "      \"start_offset\" : 7,\n",
      "      \"end_offset\" : 9,\n",
      "      \"type\" : \"<ALPHANUM>\",\n",
      "      \"position\" : 1\n",
      "    },\n",
      "    {\n",
      "      \"token\" : \"มา\",\n",
      "      \"start_offset\" : 9,\n",
      "      \"end_offset\" : 11,\n",
      "      \"type\" : \"<ALPHANUM>\",\n",
      "      \"position\" : 2\n",
      "    },\n",
      "    {\n",
      "      \"token\" : \"จาก\",\n",
      "      \"start_offset\" : 11,\n",
      "      \"end_offset\" : 14,\n",
      "      \"type\" : \"<ALPHANUM>\",\n",
      "      \"position\" : 3\n",
      "    },\n",
      "    {\n",
      "      \"token\" : \"กรุงเทพฯ\",\n",
      "      \"start_offset\" : 14,\n",
      "      \"end_offset\" : 22,\n",
      "      \"type\" : \"<ALPHANUM>\",\n",
      "      \"position\" : 4\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "curl -XGET 'localhost:9200/_analyze?tokenizer=icu_tokenizer&pretty' -H 'Content-Type: application/json' -d'\n",
    "{\n",
    "  \"text\": \"สวัสดี ผมมาจากกรุงเทพฯ\" \n",
    "}\n",
    "'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "although each character defines a word, as a whole they define something different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tokens\" : [\n",
      "    {\n",
      "      \"token\" : \"向\",\n",
      "      \"start_offset\" : 0,\n",
      "      \"end_offset\" : 1,\n",
      "      \"type\" : \"<IDEOGRAPHIC>\",\n",
      "      \"position\" : 0\n",
      "    },\n",
      "    {\n",
      "      \"token\" : \"日\",\n",
      "      \"start_offset\" : 1,\n",
      "      \"end_offset\" : 2,\n",
      "      \"type\" : \"<IDEOGRAPHIC>\",\n",
      "      \"position\" : 1\n",
      "    },\n",
      "    {\n",
      "      \"token\" : \"葵\",\n",
      "      \"start_offset\" : 2,\n",
      "      \"end_offset\" : 3,\n",
      "      \"type\" : \"<IDEOGRAPHIC>\",\n",
      "      \"position\" : 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "curl -XGET 'localhost:9200/_analyze?tokenizer=standard&pretty' -H 'Content-Type: application/json' -d'\n",
    "{\n",
    "  \"text\": \"向日葵\" \n",
    "}\n",
    "'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tokens\" : [\n",
      "    {\n",
      "      \"token\" : \"向日葵\",\n",
      "      \"start_offset\" : 0,\n",
      "      \"end_offset\" : 3,\n",
      "      \"type\" : \"<IDEOGRAPHIC>\",\n",
      "      \"position\" : 0\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "curl -XGET 'localhost:9200/_analyze?tokenizer=icu_tokenizer&pretty' -H 'Content-Type: application/json' -d'\n",
    "{\n",
    "  \"text\": \"向日葵\" \n",
    "}\n",
    "'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
